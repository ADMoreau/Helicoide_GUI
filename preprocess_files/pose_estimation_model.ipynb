{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "mount_file_id": "1huAGOXCkl1p_A7JXiL8yX-gGAbMAFx12",
      "authorship_tag": "ABX9TyMw5vfduwACgF5Fqe4lu/+A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ADMoreau/raspi_gui/blob/master/pose_estimation_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIxQpT4kdWn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall tensorflow -y\n",
        "!pip install tensorflow==2.1\n",
        "!pip install tensorflow-model-optimization\n",
        "!pip install efficientnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtB1sbAbYOOs",
        "colab_type": "code",
        "outputId": "f258a3dd-1dda-414b-e365-3fdfd42eb234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import efficientnet.tfkeras as efn \n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as tfk\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "import json\n",
        "import numpy as np\n",
        "import math\n",
        "import collections\n",
        "import PIL\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from six.moves import xrange\n",
        "import string\n",
        "#tf.compat.v1.disable_eager_execution()\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVkoJ3LfU5f8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class convolutional(layers.Layer):\n",
        "  def __init__(self, batch_normalize, filters, size, stride, pad, activation, **kwargs):\n",
        "    super(convolutional, self).__init__(**kwargs)\n",
        "    self.batch_normalize = batch_normalize\n",
        "    self.filters = filters\n",
        "    self.size = size\n",
        "    self.stride = stride\n",
        "    self.is_pad = pad\n",
        "    self.pad = 'same' if self.is_pad else 'valid'\n",
        "    self.activation = activation\n",
        "    if self.batch_normalize:\n",
        "      self.conv = layers.Conv2D(filters = self.filters, \n",
        "                                kernel_size = (self.size, self.size),\n",
        "                                strides = (self.stride, self.stride),\n",
        "                                padding = self.pad,\n",
        "                                use_bias = False)\n",
        "      self.bn = layers.BatchNormalization()\n",
        "    else:\n",
        "      self.conv = layers.Conv2D(filters = self.filters, \n",
        "                              kernel_size = (self.size, self.size),\n",
        "                              strides = (self.stride, self.stride),\n",
        "                              padding = self.pad)\n",
        "    if self.activation == 'leaky':\n",
        "      self.activation = layers.LeakyReLU(alpha=.1)\n",
        "    elif self.activation == 'relu':\n",
        "      self.activation = layers.ReLU()\n",
        "  def call(self, inputs):\n",
        "    x = self.conv(inputs)\n",
        "    if self.batch_normalize:\n",
        "      x = self.bn(x)\n",
        "    if self.activation == 'linear':\n",
        "      return x\n",
        "    else:\n",
        "      return self.activation(x)\n",
        "\n",
        "class deconvolutional(layers.Layer):\n",
        "  def __init__(self, batch_normalize, filters, size, stride, pad, activation, **kwargs):\n",
        "    super(deconvolutional, self).__init__(**kwargs)\n",
        "    self.batch_normalize = batch_normalize\n",
        "    self.filters = filters\n",
        "    self.size = size\n",
        "    self.stride = stride\n",
        "    self.is_pad = pad\n",
        "    self.pad = 'same' if self.is_pad else 'valid'\n",
        "    self.activation = activation\n",
        "    if self.batch_normalize:\n",
        "      self.conv = layers.Conv2DTranspose(filters = self.filters, \n",
        "                                kernel_size = (self.size, self.size),\n",
        "                                strides = (self.stride, self.stride),\n",
        "                                padding = self.pad,\n",
        "                                use_bias = False)\n",
        "      self.bn = layers.BatchNormalization()\n",
        "    else:\n",
        "      self.conv = layers.Conv2DTranspose(filters = self.filters, \n",
        "                              kernel_size = (self.size, self.size),\n",
        "                              strides = (self.stride, self.stride),\n",
        "                              padding = self.pad)\n",
        "    if self.activation == 'leaky':\n",
        "      self.activation = layers.LeakyReLU(alpha=.1)\n",
        "    elif self.activation == 'relu':\n",
        "      self.activation = layers.ReLU()\n",
        "  def call(self, inputs):\n",
        "    x = self.conv(inputs)\n",
        "    if self.batch_normalize:\n",
        "      x = self.bn(x)\n",
        "    if self.activation == 'linear':\n",
        "      return x\n",
        "    else:\n",
        "      return self.activation(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMwhxI2FRr4H",
        "colab_type": "text"
      },
      "source": [
        "#Model based on https://www.zpascal.net/cvpr2019/Hu_Segmentation-Driven_6D_Object_Pose_Estimation_CVPR_2019_paper.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzLL6snOeXOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def swish(x):\n",
        "  return tf.keras.layers.Multiply()([x, tf.keras.layers.Activation('sigmoid')(x)])\n",
        "\n",
        "def coreModel():\n",
        "  yolo_input = tfk.Input(shape=(480, 640, 3), name='input')\n",
        "  a = layers.Conv2D(filters=32, kernel_size=(3, 3), strides=1, padding='same')(yolo_input)\n",
        "  a = swish(layers.BatchNormalization()(a))\n",
        "  a_s = layers.Conv2D(filters=64, kernel_size=(3, 3), strides=2, padding='same')(a)\n",
        "  a_s = swish(layers.BatchNormalization()(a_s))\n",
        "  a = layers.Conv2D(filters=32, kernel_size=(1, 1), strides=1, padding='same')(a_s)\n",
        "  a = swish(layers.BatchNormalization()(a))\n",
        "  a_S = layers.Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same')(a)\n",
        "  a_S = swish(layers.BatchNormalization()(a_S))\n",
        "  #shortcut layer -3 (all)\n",
        "  b = layers.add([a_s, a_S])\n",
        "  b_s = layers.Conv2D(filters=128, kernel_size=(3, 3), strides=2, padding='same')(b)\n",
        "  b_s = swish(layers.BatchNormalization()(b_s))\n",
        "  b = layers.Conv2D(filters=64, kernel_size=(1,1), strides=1, padding='same')(b_s)\n",
        "  b = swish(layers.BatchNormalization()(b))\n",
        "  b_S = layers.Conv2D(filters=128, kernel_size=(3, 3), strides=1, padding='same')(b)\n",
        "  b_S = swish(layers.BatchNormalization()(b_S))\n",
        "  #shortcut layer\n",
        "  c_s = layers.add([b_s, b_S])\n",
        "  c = layers.Conv2D(filters=64, kernel_size=(1,1), strides=1, padding='same')(c_s)\n",
        "  c = swish(layers.BatchNormalization()(c))\n",
        "  c_S = layers.Conv2D(filters=128, kernel_size=(3, 3), strides=1, padding='same')(b)\n",
        "  c_S = swish(layers.BatchNormalization()(c_S))\n",
        "  #shortcut layer\n",
        "  d = layers.add([c_s, c_S])\n",
        "  d_s = layers.Conv2D(filters=256, kernel_size=(3, 3), strides=2, padding='same')(d)\n",
        "  d_s = swish(layers.BatchNormalization()(d_s))\n",
        "  d = layers.Conv2D(filters=128, kernel_size=(1,1), strides=1, padding='same')(d_s)\n",
        "  d = swish(layers.BatchNormalization()(d))\n",
        "  d_S = layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same')(d)\n",
        "  d_S = swish(layers.BatchNormalization()(d_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([d_s, d_S])\n",
        "  e = layers.Conv2D(filters=128, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=128, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=128, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=128, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=128, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=128, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=128, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_36 = layers.add([e_s, e_S])\n",
        "  e_s = layers.Conv2D(filters=512, kernel_size=(3,3), strides=2, padding='same')(e_36)\n",
        "  e_s = swish(layers.BatchNormalization()(e_s))\n",
        "  e = layers.Conv2D(filters=256, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=512, kernel_size=(3,3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=256, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=256, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=256, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=256, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=256, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=256, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=256, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_61 = layers.add([e_s, e_S])\n",
        "  e_s = layers.Conv2D(filters=1024, kernel_size=(3,3), strides=2, padding='same')(e_61)\n",
        "  e_s = swish(layers.BatchNormalization()(e_s))\n",
        "  e = layers.Conv2D(filters=512, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=1024, kernel_size=(3,3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=512, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=1024, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=512, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=1024, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut layer\n",
        "  e_s = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=512, kernel_size=(1,1), strides=1, padding='same')(e_s)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e_S = layers.Conv2D(filters=1024, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e_S = swish(layers.BatchNormalization()(e_S))\n",
        "  #shortcut\n",
        "  e_74 = layers.add([e_s, e_S])\n",
        "  e = layers.Conv2D(filters=512, kernel_size=(1,1), strides=1, padding='same')(e_74)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e = layers.Conv2D(filters=1024, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e = layers.Conv2D(filters=512, kernel_size=(1,1), strides=1, padding='same')(e)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e = layers.Conv2D(filters=1024, kernel_size=(3, 3), strides=1, padding='same')(e)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e = layers.Conv2D(filters=512, kernel_size=(1,1), strides=1, padding='same')(e)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  e = layers.Conv2D(filters=256, kernel_size=(1,1), strides=1, padding='same')(e)\n",
        "  e = swish(layers.BatchNormalization()(e))\n",
        "  \"\"\"\n",
        "  q = deconvolutional(batch_normalize=1, filters=256, size=2, stride=2, padding=0, activation='leaky')(q)\n",
        "  #route -1, 61\n",
        "  q = layers.Concatenate()([q, q_61])\n",
        "  q = convolutional(batch_normalize=1, filters=256, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=512, size=3, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=256, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=512, size=3, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=256, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  #q = convolutional(batch_normalize=1, filters=128, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  #q = deconvolutional(batch_normalize=1, filters=128, size=2, stride=2, pad=0, activation='leaky')(q)\n",
        "  #route -1, 36\n",
        "  q = layers.Concatenate()([q, l_36])\n",
        "  q = convolutional(batch_normalize=1, filters=128, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=256, size=3, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=128, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=256, size=3, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=128, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=256, size=3, stride=1, pad=1, activation='leaky')(q)\n",
        "  \"\"\"\n",
        "  pos = layers.Conv2D(filters=16, kernel_size=(1,1), strides=1, padding='same', name='position')(e)\n",
        "  sigmoid = layers.Conv2D(filters=8, kernel_size=(1,1), strides=1, padding='same', name='sigmoid')(e)\n",
        "  \n",
        "  yolo = tfk.Model(yolo_input, [sigmoid, pos])\n",
        "  #out = tfk.activations.sigmoid(q_outlayer_1)\n",
        "  #out = tfk.backend.max(out, axis = -1) #channels last\n",
        "  #outlayer\n",
        "  #route 74\n",
        "  \"\"\"Original moving to only classifying bounding box points \n",
        "  q = convolutional(batch_normalize=1, filters=512, size=1, stride=1, pad=1, activation='leaky')(q_74)\n",
        "  q = convolutional(batch_normalize=1, filters=1024, size=3, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=512, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=1024, size=3, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=512, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=256, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = deconvolutional(batch_normalize=1, filters=256, size=2, stride=2, pad=0, activation='leaky')(q)\n",
        "  #route -1, 61\n",
        "  q = layers.Concatenate()([q, q_61])\n",
        "  q = convolutional(batch_normalize=1, filters=256, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=512, size=3, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=256, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=512, size=3, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=256, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=128, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = deconvolutional(batch_normalize=1, filters=128, size=2, stride=2, pad=0, activation='leaky')(q)\n",
        "  #route -1 36\n",
        "  q = layers.Concatenate()([q, l_36])\n",
        "  q = convolutional(batch_normalize=1, filters=128, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=256, size=3, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=128, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=256, size=3, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=128, size=1, stride=1, pad=1, activation='leaky')(q)\n",
        "  q = convolutional(batch_normalize=1, filters=256, size=3, stride=1, pad=1, activation='leaky')(q)\n",
        "  q_outlayer_2 = convolutional(batch_normalize=0, filters=24, size=1, stride=1, pad=1, activation='linear')(q)\n",
        "  #outlayer\n",
        "  yolo = tfk.Model(yolo_input, [q_outlayer_1, q_outlayer_2])\n",
        "  \"\"\"\n",
        "  #yolo = tfk.Model(yolo_input, out)\n",
        "  return yolo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZPY_csNRTHq",
        "colab_type": "text"
      },
      "source": [
        "#Efficientnet from https://github.com/qubvel/efficientnet\n",
        "\n",
        "could not use quantization on imported model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOdETZRqX3KE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BlockArgs = collections.namedtuple('BlockArgs', [\n",
        "    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n",
        "    'expand_ratio', 'id_skip', 'strides', 'se_ratio'\n",
        "])\n",
        "# defaults will be a public argument for namedtuple in Python 3.7\n",
        "# https://docs.python.org/3/library/collections.html#collections.namedtuple\n",
        "BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n",
        "\n",
        "DEFAULT_BLOCKS_ARGS = [\n",
        "        BlockArgs(kernel_size=3, num_repeat=1, input_filters=32, output_filters=16,\n",
        "                  expand_ratio=1, id_skip=True, strides=[1, 1], se_ratio=0.25),\n",
        "        BlockArgs(kernel_size=3, num_repeat=2, input_filters=16, output_filters=24,\n",
        "                  expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
        "        BlockArgs(kernel_size=5, num_repeat=2, input_filters=24, output_filters=40,\n",
        "                  expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
        "        BlockArgs(kernel_size=3, num_repeat=3, input_filters=40, output_filters=80,\n",
        "                  expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
        "        BlockArgs(kernel_size=5, num_repeat=3, input_filters=80, output_filters=112,\n",
        "                  expand_ratio=6, id_skip=True, strides=[1, 1], se_ratio=0.25),\n",
        "        BlockArgs(kernel_size=5, num_repeat=4, input_filters=112, output_filters=192,\n",
        "                  expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
        "        BlockArgs(kernel_size=3, num_repeat=1, input_filters=192, output_filters=320,\n",
        "                  expand_ratio=6, id_skip=True, strides=[1, 1], se_ratio=0.25)\n",
        "    ]\n",
        "\n",
        "CONV_KERNEL_INITIALIZER = {\n",
        "    'class_name': 'VarianceScaling',\n",
        "    'config': {\n",
        "        'scale': 2.0,\n",
        "        'mode': 'fan_out',\n",
        "        # EfficientNet actually uses an untruncated normal distribution for\n",
        "        # initializing conv layers, but keras.initializers.VarianceScaling use\n",
        "        # a truncated distribution.\n",
        "        # We decided against a custom initializer for better serializability.\n",
        "        'distribution': 'normal'\n",
        "    }\n",
        "}\n",
        "\n",
        "DENSE_KERNEL_INITIALIZER = {\n",
        "    'class_name': 'VarianceScaling',\n",
        "    'config': {\n",
        "        'scale': 1. / 3.,\n",
        "        'mode': 'fan_out',\n",
        "        'distribution': 'uniform'\n",
        "    }\n",
        "}\n",
        "\n",
        "def get_swish():\n",
        "    def swish(x):\n",
        "        \"\"\"Swish activation function: x * sigmoid(x).\n",
        "        Reference: [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)\n",
        "        \"\"\"\n",
        "        return tf.keras.layers.Multiply()([x, tf.keras.layers.Activation('sigmoid')(x)])\n",
        "    return swish\n",
        "\n",
        "def get_dropout():\n",
        "    \"\"\"Wrapper over custom dropout. Fix problem of ``None`` shape for tf.keras.\n",
        "    It is not possible to define FixedDropout class as global object,\n",
        "    because we do not have modules for inheritance at first time.\n",
        "    Issue:\n",
        "        https://github.com/tensorflow/tensorflow/issues/30946\n",
        "    \"\"\"\n",
        "    class FixedDropout(layers.Dropout):\n",
        "        def _get_noise_shape(self, inputs):\n",
        "            if self.noise_shape is None:\n",
        "                return self.noise_shape\n",
        "\n",
        "            symbolic_shape = tfk.shape(inputs)\n",
        "            noise_shape = [symbolic_shape[axis] if shape is None else shape\n",
        "                           for axis, shape in enumerate(self.noise_shape)]\n",
        "            return tuple(noise_shape)\n",
        "\n",
        "    return FixedDropout\n",
        "\n",
        "def round_filters(filters, width_coefficient, depth_divisor):\n",
        "    \"\"\"Round number of filters based on width multiplier.\"\"\"\n",
        "\n",
        "    filters *= width_coefficient\n",
        "    new_filters = int(filters + depth_divisor / 2) // depth_divisor * depth_divisor\n",
        "    new_filters = max(depth_divisor, new_filters)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_filters < 0.9 * filters:\n",
        "        new_filters += depth_divisor\n",
        "    return int(new_filters)\n",
        "\n",
        "def round_repeats(repeats, depth_coefficient):\n",
        "    \"\"\"Round number of repeats based on depth multiplier.\"\"\"\n",
        "    return int(math.ceil(depth_coefficient * repeats))\n",
        "\n",
        "def mb_conv_block(inputs, block_args, activation, drop_rate=None, prefix='', ):\n",
        "    \"\"\"Mobile Inverted Residual Bottleneck.\"\"\"\n",
        "\n",
        "    has_se = (block_args.se_ratio is not None) and (0 < block_args.se_ratio <= 1)\n",
        "    bn_axis = 3 \n",
        "\n",
        "    # workaround over non working dropout with None in noise_shape in tf.keras\n",
        "    #Dropout = get_dropout()\n",
        "\n",
        "    # Expansion phase\n",
        "    filters = block_args.input_filters * block_args.expand_ratio\n",
        "    if block_args.expand_ratio != 1:\n",
        "        x = layers.Conv2D(filters, 1,\n",
        "                          padding='same',\n",
        "                          use_bias=False,\n",
        "                          kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
        "                          name=prefix + 'expand_conv')(inputs)\n",
        "        x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'expand_bn')(x)\n",
        "        x = layers.Activation(activation, name=prefix + 'expand_activation')(x)\n",
        "    else:\n",
        "        x = inputs\n",
        "\n",
        "    # Depthwise Convolution\n",
        "    x = layers.DepthwiseConv2D(block_args.kernel_size,\n",
        "                               strides=block_args.strides,\n",
        "                               padding='same',\n",
        "                               use_bias=False,\n",
        "                               depthwise_initializer=CONV_KERNEL_INITIALIZER,\n",
        "                               name=prefix + 'dwconv')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'bn')(x)\n",
        "    x = layers.Activation(activation, name=prefix + 'activation')(x)\n",
        "\n",
        "    # Squeeze and Excitation phase\n",
        "    if has_se:\n",
        "        num_reduced_filters = max(1, int(\n",
        "            block_args.input_filters * block_args.se_ratio\n",
        "        ))\n",
        "        se_tensor = layers.GlobalAveragePooling2D(name=prefix + 'se_squeeze')(x)\n",
        "\n",
        "        target_shape = (1, 1, filters)\n",
        "        se_tensor = layers.Reshape(target_shape, name=prefix + 'se_reshape')(se_tensor)\n",
        "        se_tensor = layers.Conv2D(num_reduced_filters, 1,\n",
        "                                  activation=activation,\n",
        "                                  padding='same',\n",
        "                                  use_bias=True,\n",
        "                                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
        "                                  name=prefix + 'se_reduce')(se_tensor)\n",
        "        se_tensor = layers.Conv2D(filters, 1,\n",
        "                                  activation='sigmoid',\n",
        "                                  padding='same',\n",
        "                                  use_bias=True,\n",
        "                                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
        "                                  name=prefix + 'se_expand')(se_tensor)\n",
        "        x = layers.multiply([x, se_tensor], name=prefix + 'se_excite')\n",
        "\n",
        "    # Output phase\n",
        "    x = layers.Conv2D(block_args.output_filters, 1,\n",
        "                      padding='same',\n",
        "                      use_bias=False,\n",
        "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
        "                      name=prefix + 'project_conv')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'project_bn')(x)\n",
        "    if block_args.id_skip and all(\n",
        "            s == 1 for s in block_args.strides\n",
        "    ) and block_args.input_filters == block_args.output_filters:\n",
        "        #if drop_rate and (drop_rate > 0):\n",
        "        #    x = Dropout(drop_rate,\n",
        "        #                noise_shape=(None, 1, 1, 1),\n",
        "        #                name=prefix + 'drop')(x)\n",
        "        x = layers.add([x, inputs], name=prefix + 'add')\n",
        "\n",
        "    return x\n",
        "\n",
        "def EfficientNet(width_coefficient,\n",
        "                 depth_coefficient,\n",
        "                 default_resolution,\n",
        "                 dropout_rate=0.2,\n",
        "                 drop_connect_rate=0.2,\n",
        "                 depth_divisor=8,\n",
        "                 model_name='efficientnet',\n",
        "                 pooling=None):\n",
        "\n",
        "    blocks_args=DEFAULT_BLOCKS_ARGS\n",
        "\n",
        "    bn_axis = 3 \n",
        "    activation = get_swish()\n",
        "\n",
        "    input_tensor = tfk.Input(shape=(480, 640, 3), name='input')\n",
        "    x = layers.Conv2D(round_filters(32, width_coefficient, depth_divisor), 3,\n",
        "                        strides=(2, 2),\n",
        "                        padding='same',\n",
        "                        use_bias=False,\n",
        "                        kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
        "                        name='stem_conv')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name='stem_bn')(x)\n",
        "    x = layers.Activation(activation, name='stem_activation')(x)\n",
        "    # Build blocks\n",
        "    num_blocks_total = sum(block_args.num_repeat for block_args in blocks_args)\n",
        "    block_num = 0\n",
        "    for idx, block_args in enumerate(blocks_args):\n",
        "        assert block_args.num_repeat > 0\n",
        "        # Update block input and output filters based on depth multiplier.\n",
        "        block_args = block_args._replace(\n",
        "            input_filters=round_filters(block_args.input_filters,\n",
        "                                        width_coefficient, depth_divisor),\n",
        "            output_filters=round_filters(block_args.output_filters,\n",
        "                                         width_coefficient, depth_divisor),\n",
        "            num_repeat=round_repeats(block_args.num_repeat, depth_coefficient))\n",
        "\n",
        "        # The first block needs to take care of stride and filter size increase.\n",
        "        drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n",
        "        x = mb_conv_block(x, block_args,\n",
        "                          activation=activation,\n",
        "                          drop_rate=drop_rate,\n",
        "                          prefix='block{}a_'.format(idx + 1))\n",
        "        block_num += 1\n",
        "        if block_args.num_repeat > 1:\n",
        "            # pylint: disable=protected-access\n",
        "            block_args = block_args._replace(\n",
        "                input_filters=block_args.output_filters, strides=[1, 1])\n",
        "            # pylint: enable=protected-access\n",
        "            for bidx in xrange(block_args.num_repeat - 1):\n",
        "                drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n",
        "                block_prefix = 'block{}{}_'.format(\n",
        "                    idx + 1,\n",
        "                    string.ascii_lowercase[bidx + 1]\n",
        "                )\n",
        "                x = mb_conv_block(x, block_args,\n",
        "                                  activation=activation,\n",
        "                                  drop_rate=drop_rate,\n",
        "                                  prefix=block_prefix)\n",
        "                block_num += 1\n",
        "\n",
        "    # Build top\n",
        "    x = layers.Conv2D(round_filters(1280, width_coefficient, depth_divisor), 1,\n",
        "                      padding='same',\n",
        "                      use_bias=False,\n",
        "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
        "                      name='top_conv')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name='top_bn')(x)\n",
        "    x = layers.Activation(activation, name='top_activation')(x)\n",
        "    pos = layers.Conv2D(filters=16,\n",
        "                        kernel_size=(1,1),\n",
        "                        strides=1,\n",
        "                        padding='same',\n",
        "                        name='position')(x)\n",
        "    sigmoid = layers.Conv2D(filters=8,\n",
        "                            kernel_size=(1,1),\n",
        "                            strides=1,\n",
        "                            padding='same',\n",
        "                            name='sigmoid')(x)\n",
        "  \n",
        "    efficientnet = tfk.Model(input_tensor, [sigmoid, pos])\n",
        "    return efficientnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSYn6wnDjn2O",
        "colab_type": "code",
        "outputId": "d73fc3b3-02a3-4613-d803-7aa1ccc6ad41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "'''\n",
        "efficientnet = EfficientNet(\n",
        "        1.0, 1.0, 224, 0.2,\n",
        "        model_name='efficientnet-b0'\n",
        "    )\n",
        "'''\n",
        "efficientnet = EfficientNet(\n",
        "        .1, .1, 100, 0.2,\n",
        "        model_name='efficientnet-b0'\n",
        "    )\n",
        "efficientnet.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, 480, 640, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "stem_conv (Conv2D)              (None, 240, 320, 8)  216         input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stem_bn (BatchNormalization)    (None, 240, 320, 8)  32          stem_conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "stem_activation (Activation)    (None, 240, 320, 8)  0           stem_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1a_dwconv (DepthwiseConv2D (None, 240, 320, 8)  72          stem_activation[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1a_bn (BatchNormalization) (None, 240, 320, 8)  32          block1a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block1a_activation (Activation) (None, 240, 320, 8)  0           block1a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_squeeze (GlobalAvera (None, 8)            0           block1a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_reshape (Reshape)    (None, 1, 1, 8)      0           block1a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_reduce (Conv2D)      (None, 1, 1, 2)      18          block1a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_expand (Conv2D)      (None, 1, 1, 8)      24          block1a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_excite (Multiply)    (None, 240, 320, 8)  0           block1a_activation[0][0]         \n",
            "                                                                 block1a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_project_conv (Conv2D)   (None, 240, 320, 8)  64          block1a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_project_bn (BatchNormal (None, 240, 320, 8)  32          block1a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block1a_add (Add)               (None, 240, 320, 8)  0           block1a_project_bn[0][0]         \n",
            "                                                                 stem_activation[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_conv (Conv2D)    (None, 240, 320, 48) 384         block1a_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_bn (BatchNormali (None, 240, 320, 48) 192         block2a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_activation (Acti (None, 240, 320, 48) 0           block2a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_dwconv (DepthwiseConv2D (None, 120, 160, 48) 432         block2a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2a_bn (BatchNormalization) (None, 120, 160, 48) 192         block2a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2a_activation (Activation) (None, 120, 160, 48) 0           block2a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_squeeze (GlobalAvera (None, 48)           0           block2a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_reshape (Reshape)    (None, 1, 1, 48)     0           block2a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_reduce (Conv2D)      (None, 1, 1, 2)      98          block2a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_expand (Conv2D)      (None, 1, 1, 48)     144         block2a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_excite (Multiply)    (None, 120, 160, 48) 0           block2a_activation[0][0]         \n",
            "                                                                 block2a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_project_conv (Conv2D)   (None, 120, 160, 8)  384         block2a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_project_bn (BatchNormal (None, 120, 160, 8)  32          block2a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_conv (Conv2D)    (None, 120, 160, 48) 384         block2a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_bn (BatchNormali (None, 120, 160, 48) 192         block3a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_activation (Acti (None, 120, 160, 48) 0           block3a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_dwconv (DepthwiseConv2D (None, 60, 80, 48)   1200        block3a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3a_bn (BatchNormalization) (None, 60, 80, 48)   192         block3a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3a_activation (Activation) (None, 60, 80, 48)   0           block3a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_squeeze (GlobalAvera (None, 48)           0           block3a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_reshape (Reshape)    (None, 1, 1, 48)     0           block3a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_reduce (Conv2D)      (None, 1, 1, 2)      98          block3a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_expand (Conv2D)      (None, 1, 1, 48)     144         block3a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_excite (Multiply)    (None, 60, 80, 48)   0           block3a_activation[0][0]         \n",
            "                                                                 block3a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_project_conv (Conv2D)   (None, 60, 80, 8)    384         block3a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_project_bn (BatchNormal (None, 60, 80, 8)    32          block3a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_conv (Conv2D)    (None, 60, 80, 48)   384         block3a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_bn (BatchNormali (None, 60, 80, 48)   192         block4a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_activation (Acti (None, 60, 80, 48)   0           block4a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_dwconv (DepthwiseConv2D (None, 30, 40, 48)   432         block4a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4a_bn (BatchNormalization) (None, 30, 40, 48)   192         block4a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4a_activation (Activation) (None, 30, 40, 48)   0           block4a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_squeeze (GlobalAvera (None, 48)           0           block4a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_reshape (Reshape)    (None, 1, 1, 48)     0           block4a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_reduce (Conv2D)      (None, 1, 1, 2)      98          block4a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_expand (Conv2D)      (None, 1, 1, 48)     144         block4a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_excite (Multiply)    (None, 30, 40, 48)   0           block4a_activation[0][0]         \n",
            "                                                                 block4a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_project_conv (Conv2D)   (None, 30, 40, 8)    384         block4a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_project_bn (BatchNormal (None, 30, 40, 8)    32          block4a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_conv (Conv2D)    (None, 30, 40, 48)   384         block4a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_bn (BatchNormali (None, 30, 40, 48)   192         block5a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_activation (Acti (None, 30, 40, 48)   0           block5a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_dwconv (DepthwiseConv2D (None, 30, 40, 48)   1200        block5a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5a_bn (BatchNormalization) (None, 30, 40, 48)   192         block5a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5a_activation (Activation) (None, 30, 40, 48)   0           block5a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_squeeze (GlobalAvera (None, 48)           0           block5a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_reshape (Reshape)    (None, 1, 1, 48)     0           block5a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_reduce (Conv2D)      (None, 1, 1, 2)      98          block5a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_expand (Conv2D)      (None, 1, 1, 48)     144         block5a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_excite (Multiply)    (None, 30, 40, 48)   0           block5a_activation[0][0]         \n",
            "                                                                 block5a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_project_conv (Conv2D)   (None, 30, 40, 16)   768         block5a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_project_bn (BatchNormal (None, 30, 40, 16)   64          block5a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_conv (Conv2D)    (None, 30, 40, 96)   1536        block5a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_bn (BatchNormali (None, 30, 40, 96)   384         block6a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_activation (Acti (None, 30, 40, 96)   0           block6a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_dwconv (DepthwiseConv2D (None, 15, 20, 96)   2400        block6a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6a_bn (BatchNormalization) (None, 15, 20, 96)   384         block6a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6a_activation (Activation) (None, 15, 20, 96)   0           block6a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_squeeze (GlobalAvera (None, 96)           0           block6a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block6a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block6a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block6a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_excite (Multiply)    (None, 15, 20, 96)   0           block6a_activation[0][0]         \n",
            "                                                                 block6a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_project_conv (Conv2D)   (None, 15, 20, 24)   2304        block6a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_project_bn (BatchNormal (None, 15, 20, 24)   96          block6a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_conv (Conv2D)    (None, 15, 20, 144)  3456        block6a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_bn (BatchNormali (None, 15, 20, 144)  576         block7a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_activation (Acti (None, 15, 20, 144)  0           block7a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_dwconv (DepthwiseConv2D (None, 15, 20, 144)  1296        block7a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block7a_bn (BatchNormalization) (None, 15, 20, 144)  576         block7a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block7a_activation (Activation) (None, 15, 20, 144)  0           block7a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_squeeze (GlobalAvera (None, 144)          0           block7a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block7a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block7a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block7a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_excite (Multiply)    (None, 15, 20, 144)  0           block7a_activation[0][0]         \n",
            "                                                                 block7a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_project_conv (Conv2D)   (None, 15, 20, 32)   4608        block7a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_project_bn (BatchNormal (None, 15, 20, 32)   128         block7a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "top_conv (Conv2D)               (None, 15, 20, 128)  4096        block7a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "top_bn (BatchNormalization)     (None, 15, 20, 128)  512         top_conv[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "top_activation (Activation)     (None, 15, 20, 128)  0           top_bn[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "sigmoid (Conv2D)                (None, 15, 20, 8)    1032        top_activation[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "position (Conv2D)               (None, 15, 20, 16)   2064        top_activation[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 38,068\n",
            "Trainable params: 35,844\n",
            "Non-trainable params: 2,224\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYlP2d9_JsE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/pose_estimation/via_export_json.json') as f:\n",
        "  data = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJpMrqk8LmZ9",
        "colab_type": "code",
        "outputId": "ac3cbdd7-6f0c-43f8-cd9a-9a89c4806118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_frame = np.zeros(shape=(len(data), 480, 640, 3))\n",
        "position_frame = np.zeros(shape=(len(data), 15, 20, 16))\n",
        "sigmoid_frame = np.zeros(shape=(len(data), 15, 20, 8))\n",
        "\n",
        "for i, val in tqdm(enumerate(data)):\n",
        "  rgb_image = PIL.Image.open(\"/content/drive/My Drive/pose_estimation/test_images/{}\".format(data[val]['filename'].\n",
        "                                                                                             replace('.png', '.jpg')))\n",
        "  rgb_image = np.array(rgb_image)\n",
        "  input_frame[i, :, :, :] = rgb_image\n",
        "  for point in data[val]['regions']:\n",
        "    x = point['shape_attributes']['cx']\n",
        "    y = point['shape_attributes']['cy']\n",
        "    sig_x = math.floor(x / 32)\n",
        "    sig_y = math.floor(y / 32)\n",
        "    label = point['region_attributes']['point_name']\n",
        "    if label == 'ft':\n",
        "      sigmoid_frame[i, sig_y, sig_x, 0] = 1\n",
        "      for a in range(15):\n",
        "        for b in range(20):\n",
        "          position_frame[i, a, b, 0] = (x - ((32 * a) + 15)) / 640 #x positions\n",
        "          position_frame[i, a, b, 1] = (y - ((32 * b) + 15)) / 480 #y positions\n",
        "    elif label == 'fl':\n",
        "      sigmoid_frame[i, sig_y, sig_x, 1] = 1\n",
        "      for a in range(15):\n",
        "        for b in range(20):\n",
        "          position_frame[i, a, b, 2] = (x - ((32 * a) + 15)) / 640 #x positions\n",
        "          position_frame[i, a, b, 3] = (y - ((32 * b) + 15)) / 480 #y positions\n",
        "    elif label == 'fb':\n",
        "      sigmoid_frame[i, sig_y, sig_x, 2] = 1\n",
        "      for a in range(15):\n",
        "        for b in range(20):\n",
        "          position_frame[i, a, b, 4] = (x - ((32 * a) + 15)) / 640 #x positions\n",
        "          position_frame[i, a, b, 5] = (y - ((32 * b) + 15)) / 480 #y positions\n",
        "    elif label == 'fr':\n",
        "      sigmoid_frame[i, sig_y, sig_x, 3] = 1\n",
        "      for a in range(15):\n",
        "        for b in range(20):\n",
        "          position_frame[i, a, b, 6] = (x - ((32 * a) + 15)) / 640 #x positions\n",
        "          position_frame[i, a, b, 7] = (y - ((32 * b) + 15)) / 480 #y positions\n",
        "    elif label == 'bt':\n",
        "      sigmoid_frame[i, sig_y, sig_x, 4] = 1\n",
        "      for a in range(15):\n",
        "        for b in range(20):\n",
        "          position_frame[i, a, b, 8] = (x - ((32 * a) + 15)) / 640 #x positions\n",
        "          position_frame[i, a, b, 9] = (y - ((32 * b) + 15)) / 480 #y positions\n",
        "    elif label == 'bl':\n",
        "      sigmoid_frame[i, sig_y, sig_x, 5] = 1\n",
        "      for a in range(15):\n",
        "        for b in range(20):\n",
        "          position_frame[i, a, b, 10] = (x - ((32 * a) + 15)) / 640 #x positions\n",
        "          position_frame[i, a, b, 11] = (y - ((32 * b) + 15)) / 480 #y positions\n",
        "    elif label == 'bb':\n",
        "      sigmoid_frame[i, sig_y, sig_x, 6] = 1\n",
        "      for a in range(15):\n",
        "        for b in range(20):\n",
        "          position_frame[i, a, b, 12] = (x - ((32 * a) + 15)) / 640 #x positions\n",
        "          position_frame[i, a, b, 13] = (y - ((32 * b) + 15)) / 480 #y positions\n",
        "    elif label == 'br':\n",
        "      sigmoid_frame[i, sig_y, sig_x, 7] = 1\n",
        "      for a in range(15):\n",
        "        for b in range(20):\n",
        "          position_frame[i, a, b, 14] = (x - ((32 * a) + 15)) / 640 #x positions\n",
        "          position_frame[i, a, b, 15] = (y - ((32 * b) + 15)) / 480 #y positions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99it [01:22,  1.20it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vl7fd0cUbsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = (input_frame / 255.0).astype(np.float32)\n",
        "y_sigmoid = sigmoid_frame.astype(np.float32)\n",
        "y_pos = position_frame.astype(np.float32)\n",
        "\n",
        "X_train, X_test = X[:80], X[80:],\n",
        "y_train_sigmoid, y_test_sigmoid = y_sigmoid[:80], y_sigmoid[80:]\n",
        "y_train_pos, y_test_pos = y_pos[:80], y_pos[80:]\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, {\"sigmoid\": y_train_sigmoid, \"position\": y_train_pos}))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, {\"sigmoid\": y_test_sigmoid, \"position\": y_test_pos}))\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "train_dataset = train_dataset.shuffle(1).batch(4).prefetch(AUTO)\n",
        "test_dataset = test_dataset.shuffle(1).batch(4).prefetch(AUTO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esOFw3-idNVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(model, x, y):\n",
        "  predictions = model(x)\n",
        "  true_foci, true_loc = y['sigmoid'], y['position']\n",
        "  predict_foci, predict_loc = tfk.activations.sigmoid(predictions[0]), predictions[1]\n",
        "\n",
        "  def loss_object(true_foci, true_loc, predict_foci, predict_loc):\n",
        "    #Positional L1 loss\n",
        "    delta_c = tf.math.subtract(true_loc, predict_loc)\n",
        "    delta_c = tf.math.abs(delta_c)\n",
        "    #get Tau\n",
        "    delta_c_max = tf.math.reduce_max(delta_c)\n",
        "    delta_c_min = tf.math.reduce_min(delta_c)\n",
        "    tau = -1 * (delta_c_max - delta_c_min) / (delta_c_max + delta_c_min)\n",
        "    #L2\n",
        "    temp = tf.math.subtract(true_loc, predict_loc)\n",
        "    temp = tf.math.square(temp)\n",
        "    #multiply by Tau and exp\n",
        "    temp = tf.math.scalar_mul(tau, temp)\n",
        "    temp = tf.math.exp(temp)\n",
        "    #reduce the dimension of the temp array\n",
        "    a1 = temp[:, :, :, 0]\n",
        "    a2 = temp[:, :, :, 1]\n",
        "    a = tf.math.add(a1, a2)\n",
        "    a = tf.scalar_mul(.5, a)\n",
        "\n",
        "    b1 = temp[:, :, :, 2]\n",
        "    b2 = temp[:, :, :, 3]\n",
        "    b = tf.math.add(b1, b2)\n",
        "    b = tf.scalar_mul(.5, b)\n",
        "\n",
        "    c1 = temp[:, :, :, 4]\n",
        "    c2 = temp[:, :, :, 5]\n",
        "    c = tf.math.add(c1, c2)\n",
        "    c = tf.scalar_mul(.5, c)\n",
        "\n",
        "    d1 = temp[:, :, :, 6]\n",
        "    d2 = temp[:, :, :, 7]\n",
        "    d = tf.math.add(d1, d2)\n",
        "    d = tf.scalar_mul(.5, d)\n",
        "\n",
        "    e1 = temp[:, :, :, 8]\n",
        "    e2 = temp[:, :, :, 9]\n",
        "    e = tf.math.add(e1, e2)\n",
        "    e = tf.scalar_mul(.5, e)\n",
        "\n",
        "    f1 = temp[:, :, :, 10]\n",
        "    f2 = temp[:, :, :, 11]\n",
        "    f = tf.math.add(f1, f2)\n",
        "    f = tf.scalar_mul(.5, f)\n",
        "\n",
        "    g1 = temp[:, :, :, 12]\n",
        "    g2 = temp[:, :, :, 13]\n",
        "    g = tf.math.add(g1, g2)\n",
        "    g = tf.scalar_mul(.5, g)\n",
        "\n",
        "    h1 = temp[:, :, :, 14]\n",
        "    h2 = temp[:, :, :, 15]\n",
        "    h = tf.math.add(h1, h2)\n",
        "    h = tf.scalar_mul(.5, h)\n",
        "    temp = tf.stack([a, b, c, d, e, f, g, h], axis=3)\n",
        "\n",
        "    #L1\n",
        "    temp = tf.math.subtract(predict_foci, temp)\n",
        "    temp = tf.math.abs(temp)\n",
        "    \n",
        "    beta = 1\n",
        "    gamma = 1\n",
        "    position_loss = tf.math.reduce_sum(delta_c)\n",
        "    conf_loss = tf.math.reduce_sum(temp)\n",
        "    loss = beta * position_loss + gamma * conf_loss\n",
        "    loss = loss / true_foci.shape[0] #BATCH SIZE ?\n",
        "    return loss\n",
        "\n",
        "  return loss_object(true_foci, true_loc, predict_foci, predict_loc)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2b6ZMIM60ED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = custom_loss(model, inputs, targets)\n",
        "  return loss_value, tape.gradient(loss_value, model.trainable_variables)\n",
        "\n",
        "optimizer = tfk.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUO9Yo85JroP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_file = '/content/drive/My Drive/pose_estimation/efficientnet.h5'\n",
        "num_epochs = 300\n",
        "num_train_samples = 80\n",
        "batch_size = 4\n",
        "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * num_epochs\n",
        "new_pruning_params = {\n",
        "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                   final_sparsity=0.95,\n",
        "                                                   begin_step=100,\n",
        "                                                   end_step=end_step,\n",
        "                                                   frequency=20)\n",
        "}\n",
        "\n",
        "coreModel = sparsity.prune_low_magnitude(efficientnet, **new_pruning_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S308PbJe678l",
        "colab_type": "code",
        "outputId": "44aa6604-3e5f-4eec-e583-75a9e148128f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  best = math.inf\n",
        "  for x, y in train_dataset:\n",
        "    loss_value, grads = grad(efficientnet, x, y)\n",
        "    optimizer.apply_gradients(zip(grads, efficientnet.trainable_variables))\n",
        "    epoch_loss_avg(loss_value)\n",
        "  print(\"Epoch {:03d}: Loss: {:.3f}\".format(epoch, epoch_loss_avg.result()))\n",
        "  sparsity.UpdatePruningStep()\n",
        "  if float(epoch_loss_avg.result()) < best:\n",
        "    best = epoch_loss_avg.result()\n",
        "    tf.keras.models.save_model(efficientnet, checkpoint_file, include_optimizer=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000: Loss: 2074.397\n",
            "Epoch 001: Loss: 1650.071\n",
            "Epoch 002: Loss: 1396.481\n",
            "Epoch 003: Loss: 1274.292\n",
            "Epoch 004: Loss: 1212.144\n",
            "Epoch 005: Loss: 1162.082\n",
            "Epoch 006: Loss: 1129.366\n",
            "Epoch 007: Loss: 1080.897\n",
            "Epoch 008: Loss: 1076.704\n",
            "Epoch 009: Loss: 1048.339\n",
            "Epoch 010: Loss: 1031.123\n",
            "Epoch 011: Loss: 1023.201\n",
            "Epoch 012: Loss: 1008.259\n",
            "Epoch 013: Loss: 1001.447\n",
            "Epoch 014: Loss: 991.928\n",
            "Epoch 015: Loss: 986.772\n",
            "Epoch 016: Loss: 981.104\n",
            "Epoch 017: Loss: 977.490\n",
            "Epoch 018: Loss: 969.831\n",
            "Epoch 019: Loss: 963.237\n",
            "Epoch 020: Loss: 956.676\n",
            "Epoch 021: Loss: 942.596\n",
            "Epoch 022: Loss: 947.284\n",
            "Epoch 023: Loss: 941.282\n",
            "Epoch 024: Loss: 925.814\n",
            "Epoch 025: Loss: 915.160\n",
            "Epoch 026: Loss: 931.739\n",
            "Epoch 027: Loss: 908.804\n",
            "Epoch 028: Loss: 902.888\n",
            "Epoch 029: Loss: 871.364\n",
            "Epoch 030: Loss: 852.749\n",
            "Epoch 031: Loss: 845.628\n",
            "Epoch 032: Loss: 802.582\n",
            "Epoch 033: Loss: 804.998\n",
            "Epoch 034: Loss: 755.671\n",
            "Epoch 035: Loss: 733.397\n",
            "Epoch 036: Loss: 742.251\n",
            "Epoch 037: Loss: 724.123\n",
            "Epoch 038: Loss: 696.598\n",
            "Epoch 039: Loss: 688.037\n",
            "Epoch 040: Loss: 676.233\n",
            "Epoch 041: Loss: 669.275\n",
            "Epoch 042: Loss: 658.344\n",
            "Epoch 043: Loss: 654.006\n",
            "Epoch 044: Loss: 650.523\n",
            "Epoch 045: Loss: 648.315\n",
            "Epoch 046: Loss: 642.083\n",
            "Epoch 047: Loss: 635.917\n",
            "Epoch 048: Loss: 633.674\n",
            "Epoch 049: Loss: 627.283\n",
            "Epoch 050: Loss: 627.637\n",
            "Epoch 051: Loss: 624.034\n",
            "Epoch 052: Loss: 631.037\n",
            "Epoch 053: Loss: 621.174\n",
            "Epoch 054: Loss: 618.070\n",
            "Epoch 055: Loss: 611.469\n",
            "Epoch 056: Loss: 609.628\n",
            "Epoch 057: Loss: 606.629\n",
            "Epoch 058: Loss: 606.387\n",
            "Epoch 059: Loss: 599.663\n",
            "Epoch 060: Loss: 610.742\n",
            "Epoch 061: Loss: 597.301\n",
            "Epoch 062: Loss: 591.249\n",
            "Epoch 063: Loss: 597.836\n",
            "Epoch 064: Loss: 602.125\n",
            "Epoch 065: Loss: 593.832\n",
            "Epoch 066: Loss: 586.087\n",
            "Epoch 067: Loss: 593.365\n",
            "Epoch 068: Loss: 585.444\n",
            "Epoch 069: Loss: 583.437\n",
            "Epoch 070: Loss: 589.091\n",
            "Epoch 071: Loss: 575.470\n",
            "Epoch 072: Loss: 569.063\n",
            "Epoch 073: Loss: 564.237\n",
            "Epoch 074: Loss: 566.711\n",
            "Epoch 075: Loss: 555.327\n",
            "Epoch 076: Loss: 561.626\n",
            "Epoch 077: Loss: 561.635\n",
            "Epoch 078: Loss: 568.166\n",
            "Epoch 079: Loss: 551.487\n",
            "Epoch 080: Loss: 539.933\n",
            "Epoch 081: Loss: 543.150\n",
            "Epoch 082: Loss: 548.996\n",
            "Epoch 083: Loss: 538.527\n",
            "Epoch 084: Loss: 530.208\n",
            "Epoch 085: Loss: 520.281\n",
            "Epoch 086: Loss: 522.953\n",
            "Epoch 087: Loss: 519.774\n",
            "Epoch 088: Loss: 515.941\n",
            "Epoch 089: Loss: 510.581\n",
            "Epoch 090: Loss: 502.213\n",
            "Epoch 091: Loss: 505.496\n",
            "Epoch 092: Loss: 495.521\n",
            "Epoch 093: Loss: 479.135\n",
            "Epoch 094: Loss: 485.484\n",
            "Epoch 095: Loss: 475.282\n",
            "Epoch 096: Loss: 468.380\n",
            "Epoch 097: Loss: 463.902\n",
            "Epoch 098: Loss: 453.382\n",
            "Epoch 099: Loss: 456.265\n",
            "Epoch 100: Loss: 445.771\n",
            "Epoch 101: Loss: 432.776\n",
            "Epoch 102: Loss: 421.396\n",
            "Epoch 103: Loss: 406.910\n",
            "Epoch 104: Loss: 403.250\n",
            "Epoch 105: Loss: 406.672\n",
            "Epoch 106: Loss: 412.736\n",
            "Epoch 107: Loss: 390.944\n",
            "Epoch 108: Loss: 385.754\n",
            "Epoch 109: Loss: 388.934\n",
            "Epoch 110: Loss: 389.011\n",
            "Epoch 111: Loss: 376.583\n",
            "Epoch 112: Loss: 366.447\n",
            "Epoch 113: Loss: 361.613\n",
            "Epoch 114: Loss: 360.386\n",
            "Epoch 115: Loss: 359.698\n",
            "Epoch 116: Loss: 351.130\n",
            "Epoch 117: Loss: 357.426\n",
            "Epoch 118: Loss: 374.245\n",
            "Epoch 119: Loss: 406.727\n",
            "Epoch 120: Loss: 419.494\n",
            "Epoch 121: Loss: 377.102\n",
            "Epoch 122: Loss: 372.350\n",
            "Epoch 123: Loss: 354.152\n",
            "Epoch 124: Loss: 342.522\n",
            "Epoch 125: Loss: 329.253\n",
            "Epoch 126: Loss: 329.960\n",
            "Epoch 127: Loss: 322.032\n",
            "Epoch 128: Loss: 314.825\n",
            "Epoch 129: Loss: 317.898\n",
            "Epoch 130: Loss: 318.768\n",
            "Epoch 131: Loss: 317.177\n",
            "Epoch 132: Loss: 310.350\n",
            "Epoch 133: Loss: 322.054\n",
            "Epoch 134: Loss: 333.948\n",
            "Epoch 135: Loss: 329.388\n",
            "Epoch 136: Loss: 316.886\n",
            "Epoch 137: Loss: 311.843\n",
            "Epoch 138: Loss: 314.074\n",
            "Epoch 139: Loss: 306.757\n",
            "Epoch 140: Loss: 299.410\n",
            "Epoch 141: Loss: 298.703\n",
            "Epoch 142: Loss: 295.089\n",
            "Epoch 143: Loss: 295.411\n",
            "Epoch 144: Loss: 291.257\n",
            "Epoch 145: Loss: 292.874\n",
            "Epoch 146: Loss: 295.211\n",
            "Epoch 147: Loss: 295.636\n",
            "Epoch 148: Loss: 302.166\n",
            "Epoch 149: Loss: 295.340\n",
            "Epoch 150: Loss: 297.855\n",
            "Epoch 151: Loss: 290.198\n",
            "Epoch 152: Loss: 291.395\n",
            "Epoch 153: Loss: 290.434\n",
            "Epoch 154: Loss: 290.267\n",
            "Epoch 155: Loss: 287.901\n",
            "Epoch 156: Loss: 293.888\n",
            "Epoch 157: Loss: 291.117\n",
            "Epoch 158: Loss: 292.031\n",
            "Epoch 159: Loss: 290.182\n",
            "Epoch 160: Loss: 289.299\n",
            "Epoch 161: Loss: 281.941\n",
            "Epoch 162: Loss: 282.818\n",
            "Epoch 163: Loss: 288.636\n",
            "Epoch 164: Loss: 283.676\n",
            "Epoch 165: Loss: 287.495\n",
            "Epoch 166: Loss: 304.376\n",
            "Epoch 167: Loss: 311.310\n",
            "Epoch 168: Loss: 283.746\n",
            "Epoch 169: Loss: 286.008\n",
            "Epoch 170: Loss: 287.892\n",
            "Epoch 171: Loss: 280.770\n",
            "Epoch 172: Loss: 290.731\n",
            "Epoch 173: Loss: 293.161\n",
            "Epoch 174: Loss: 278.806\n",
            "Epoch 175: Loss: 306.392\n",
            "Epoch 176: Loss: 299.570\n",
            "Epoch 177: Loss: 287.722\n",
            "Epoch 178: Loss: 308.070\n",
            "Epoch 179: Loss: 291.664\n",
            "Epoch 180: Loss: 286.070\n",
            "Epoch 181: Loss: 286.145\n",
            "Epoch 182: Loss: 274.002\n",
            "Epoch 183: Loss: 274.922\n",
            "Epoch 184: Loss: 281.427\n",
            "Epoch 185: Loss: 284.158\n",
            "Epoch 186: Loss: 293.587\n",
            "Epoch 187: Loss: 289.291\n",
            "Epoch 188: Loss: 293.388\n",
            "Epoch 189: Loss: 287.617\n",
            "Epoch 190: Loss: 279.895\n",
            "Epoch 191: Loss: 276.533\n",
            "Epoch 192: Loss: 267.656\n",
            "Epoch 193: Loss: 273.377\n",
            "Epoch 194: Loss: 277.552\n",
            "Epoch 195: Loss: 273.755\n",
            "Epoch 196: Loss: 272.884\n",
            "Epoch 197: Loss: 272.843\n",
            "Epoch 198: Loss: 283.542\n",
            "Epoch 199: Loss: 275.147\n",
            "Epoch 200: Loss: 291.486\n",
            "Epoch 201: Loss: 278.751\n",
            "Epoch 202: Loss: 270.741\n",
            "Epoch 203: Loss: 262.646\n",
            "Epoch 204: Loss: 264.389\n",
            "Epoch 205: Loss: 273.659\n",
            "Epoch 206: Loss: 275.634\n",
            "Epoch 207: Loss: 272.821\n",
            "Epoch 208: Loss: 280.457\n",
            "Epoch 209: Loss: 265.844\n",
            "Epoch 210: Loss: 264.116\n",
            "Epoch 211: Loss: 256.348\n",
            "Epoch 212: Loss: 254.731\n",
            "Epoch 213: Loss: 250.547\n",
            "Epoch 214: Loss: 247.857\n",
            "Epoch 215: Loss: 255.801\n",
            "Epoch 216: Loss: 254.301\n",
            "Epoch 217: Loss: 253.054\n",
            "Epoch 218: Loss: 251.715\n",
            "Epoch 219: Loss: 247.786\n",
            "Epoch 220: Loss: 258.146\n",
            "Epoch 221: Loss: 255.829\n",
            "Epoch 222: Loss: 249.806\n",
            "Epoch 223: Loss: 251.321\n",
            "Epoch 224: Loss: 253.456\n",
            "Epoch 225: Loss: 249.451\n",
            "Epoch 226: Loss: 251.600\n",
            "Epoch 227: Loss: 257.488\n",
            "Epoch 228: Loss: 251.464\n",
            "Epoch 229: Loss: 252.398\n",
            "Epoch 230: Loss: 248.557\n",
            "Epoch 231: Loss: 252.168\n",
            "Epoch 232: Loss: 253.816\n",
            "Epoch 233: Loss: 250.535\n",
            "Epoch 234: Loss: 250.043\n",
            "Epoch 235: Loss: 251.377\n",
            "Epoch 236: Loss: 246.678\n",
            "Epoch 237: Loss: 245.460\n",
            "Epoch 238: Loss: 238.321\n",
            "Epoch 239: Loss: 237.686\n",
            "Epoch 240: Loss: 254.480\n",
            "Epoch 241: Loss: 245.114\n",
            "Epoch 242: Loss: 242.776\n",
            "Epoch 243: Loss: 235.285\n",
            "Epoch 244: Loss: 241.413\n",
            "Epoch 245: Loss: 233.231\n",
            "Epoch 246: Loss: 236.625\n",
            "Epoch 247: Loss: 251.874\n",
            "Epoch 248: Loss: 242.696\n",
            "Epoch 249: Loss: 246.316\n",
            "Epoch 250: Loss: 242.720\n",
            "Epoch 251: Loss: 252.387\n",
            "Epoch 252: Loss: 245.159\n",
            "Epoch 253: Loss: 242.104\n",
            "Epoch 254: Loss: 233.021\n",
            "Epoch 255: Loss: 241.092\n",
            "Epoch 256: Loss: 231.900\n",
            "Epoch 257: Loss: 236.011\n",
            "Epoch 258: Loss: 243.159\n",
            "Epoch 259: Loss: 229.440\n",
            "Epoch 260: Loss: 227.196\n",
            "Epoch 261: Loss: 229.713\n",
            "Epoch 262: Loss: 222.068\n",
            "Epoch 263: Loss: 219.269\n",
            "Epoch 264: Loss: 222.492\n",
            "Epoch 265: Loss: 218.517\n",
            "Epoch 266: Loss: 219.011\n",
            "Epoch 267: Loss: 228.756\n",
            "Epoch 268: Loss: 238.847\n",
            "Epoch 269: Loss: 228.205\n",
            "Epoch 270: Loss: 222.774\n",
            "Epoch 271: Loss: 229.789\n",
            "Epoch 272: Loss: 226.909\n",
            "Epoch 273: Loss: 219.291\n",
            "Epoch 274: Loss: 218.751\n",
            "Epoch 275: Loss: 231.874\n",
            "Epoch 276: Loss: 237.967\n",
            "Epoch 277: Loss: 237.693\n",
            "Epoch 278: Loss: 228.865\n",
            "Epoch 279: Loss: 232.861\n",
            "Epoch 280: Loss: 236.449\n",
            "Epoch 281: Loss: 242.965\n",
            "Epoch 282: Loss: 230.275\n",
            "Epoch 283: Loss: 231.417\n",
            "Epoch 284: Loss: 228.145\n",
            "Epoch 285: Loss: 223.983\n",
            "Epoch 286: Loss: 225.474\n",
            "Epoch 287: Loss: 228.255\n",
            "Epoch 288: Loss: 226.700\n",
            "Epoch 289: Loss: 227.922\n",
            "Epoch 290: Loss: 220.600\n",
            "Epoch 291: Loss: 217.465\n",
            "Epoch 292: Loss: 212.467\n",
            "Epoch 293: Loss: 212.619\n",
            "Epoch 294: Loss: 211.648\n",
            "Epoch 295: Loss: 208.882\n",
            "Epoch 296: Loss: 209.192\n",
            "Epoch 297: Loss: 217.824\n",
            "Epoch 298: Loss: 214.605\n",
            "Epoch 299: Loss: 214.970\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwrsCG5AJ-t7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_model = sparsity.strip_pruning(efficientnet)\n",
        "tf.keras.models.save_model(final_model,\n",
        "                           '/content/drive/My Drive/pose_estimation/pruned_efficientnet2.h5',\n",
        "                           include_optimizer=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftp1EinKLdqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "tflite_quant_model_file = '/content/drive/My Drive/pose_estimation/efficient_sparse_quant2.tflite'\n",
        "with open(tflite_quant_model_file, 'wb') as f:\n",
        "  f.write(tflite_quant_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4l42kXV3_bW",
        "colab_type": "code",
        "outputId": "3de76564-860d-4e0c-b906-f6308c0c03a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "restored_model = tf.keras.models.load_model('/content/drive/My Drive/pose_estimation/pruned_model.h5')\n",
        "restored_model.compile()\n",
        "score = restored_model.evaluate(test_dataset, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:Output sigmoid missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to sigmoid.\n",
            "WARNING:tensorflow:Output position missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to position.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-854bc289eb65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrestored_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/pose_estimation/pruned_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrestored_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestored_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m       \u001b[0;31m# Creates the model loss and weighted metrics sub-graphs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_weights_loss_and_weighted_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m       \u001b[0;31m# Functions for train, test and predict will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_compile_weights_loss_and_weighted_metrics\u001b[0;34m(self, sample_weights)\u001b[0m\n\u001b[1;32m   1590\u001b[0m       \u001b[0;31m#                   loss_weight_2 * output_2_loss_fn(...) +\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m       \u001b[0;31m#                   layer losses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_total_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_skip_target_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_prepare_total_loss\u001b[0;34m(self, masks)\u001b[0m\n\u001b[1;32m   1689\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m           raise ValueError('The model cannot be compiled '\n\u001b[0m\u001b[1;32m   1692\u001b[0m                            'because it has no loss to optimize.')\n\u001b[1;32m   1693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The model cannot be compiled because it has no loss to optimize."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1D9rC_fMOdg",
        "colab_type": "code",
        "outputId": "1442296b-656b-4fce-b107-35e1e88a5ab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "final_model = sparsity.strip_pruning(pruned_model)\n",
        "final_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1fac094313b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparsity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_pruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpruned_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pruned_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJA54dvNVgNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compressionModel = tfk.models.load_model(\"/content/drive/My Drive/pose_estimation/weights\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqsKZTBJ0ICn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "checkpoint_directory = \"/content/drive/My Drive/pose_estimation/training_checkpoints\"\n",
        "checkpoint_prefix = os.path.join(checkpoint_directory, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(model=compressionModel)\n",
        "checkpoint.save(file_prefix=checkpoint_prefix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CC6QxhG910i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras_file = \"/content/drive/My Drive/pose_estimation/weights.h5\"\n",
        "tf.keras.models.save_model(compressionModel, keras_file, include_optimizer=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKoE7Zzhwp7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = coreModel()\n",
        "test.load_weights(\"/content/drive/My Drive/pose_estimation/training_checkpoints/ckpt-1.index\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxik3h1Cswku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loadedmodel = tfk.models.load_model(\"/content/drive/My Drive/pose_estimation/training_checkpoints\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5F1qjV4rHbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "\n",
        "epochs = 5\n",
        "num_train_samples = 80\n",
        "batch_size = 4\n",
        "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
        "new_pruning_params = {\n",
        "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                   final_sparsity=0.90,\n",
        "                                                   begin_step=0,\n",
        "                                                   end_step=end_step,\n",
        "                                                   frequency=100)\n",
        "}\n",
        "with prune.prune_scope():\n",
        "  model = tfk.models.load_model(\"/content/drive/My Drive/pose_estimation/weights\")\n",
        "\n",
        "new_pruned_model = sparsity.prune_low_magnitude(model, **new_pruning_params)\n",
        "new_pruned_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kU8oYO0qyYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  best = math.inf\n",
        "  for x, y in train_dataset:\n",
        "    loss_value, grads = grad(coreModel, x, y)\n",
        "    optimizer.apply_gradients(zip(grads, coreModel.trainable_variables))\n",
        "    epoch_loss_avg(loss_value)\n",
        "  print(\"Epoch {:03d}: Loss: {:.3f}\".format(epoch, epoch_loss_avg.result()))\n",
        "  sparsity.UpdatePruningStep()\n",
        "  if epoch_loss_avg.result() < best:\n",
        "    best = epoch_loss_avg.result()\n",
        "    coreModel.save('/content/drive/My Drive/pose_estimation/weights')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFxWcuV3mH_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tfk.models.load_model(\"/content/drive/My Drive/pose_estimation/weights\")\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27uW9_d5nRha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rgb_image = PIL.Image.open(\"/content/drive/My Drive/pose_estimation/test_images/image_90.jpg\")\n",
        "rgb_image = np.array(rgb_image) / 255.0\n",
        "rgb_image = np.expand_dims(rgb_image, axis=0)\n",
        "img = tf.convert_to_tensor(rgb_image, dtype=tf.float32)\n",
        "result = model.predict(img)\n",
        "result[0].shape, result[1].shape #, result[0], result[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgFQnc8_yPTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = result[0][:, :, :, 1].squeeze()\n",
        "b = a.flatten()\n",
        "ind = np.argpartition(b, -40)[-40:]\n",
        "print(b[ind])\n",
        "points = []\n",
        "for i in b[ind]:\n",
        "  points.append(np.where(a == i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElflDUwy6juM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "points = np.array(points).squeeze()\n",
        "print(points)\n",
        "print(points.shape)\n",
        "rgb = result[1].squeeze()\n",
        "print(rgb.shape)\n",
        "p = []\n",
        "for point in points:\n",
        "  x = rgb[point[0], point[1], 2]\n",
        "  y = rgb[point[0], point[1], 3] \n",
        "\n",
        "  x = ((32 * point[0]) + 15) + (x * 640) #x positions\n",
        "  y = ((32 * point[1]) + 15) + (y * 480) #y positions\n",
        "  p.append([x, y])\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knMMpGQsrBSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = result[:, :, :, 1].flatten()\n",
        "tops = temp.argsort()[-100:]\n",
        "vals = np.unravel_index(tops, result[:, :, :, 1].shape)\n",
        "vals[1].mean(), vals[2].mean()\n",
        "#np.where(result[:, :, :, 1] == np.amax(result[:, :, :, 1]))\n",
        "#np.where(result[:, :, :, 2] == np.amax(result[:, :, :, 2]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}