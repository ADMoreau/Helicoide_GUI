{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "1TfKQ_zmXbv8",
    "outputId": "2f81c5b8-3220-4592-f45a-0a2682d516b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-model-optimization\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/7e/e94aa029999ec30951e8129fa992fecbbaffda66eba97c65d5a83f8ea96d/tensorflow_model_optimization-0.3.0-py2.py3-none-any.whl (165kB)\n",
      "\r",
      "\u001b[K     |██                              | 10kB 24.3MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 20kB 5.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 30kB 7.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 40kB 8.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 51kB 7.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 61kB 8.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 71kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 81kB 8.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 92kB 7.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 102kB 8.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 112kB 8.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 122kB 8.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 133kB 8.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 143kB 8.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 153kB 8.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 163kB 8.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 174kB 8.0MB/s \n",
      "\u001b[?25hCollecting dm-tree~=0.1.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/48/10fb721334810081b7e6eebeba0d12e12126c76993e8c243062d2f56a89f/dm_tree-0.1.5-cp36-cp36m-manylinux1_x86_64.whl (294kB)\n",
      "\r",
      "\u001b[K     |█▏                              | 10kB 24.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 20kB 32.0MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 30kB 37.1MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 40kB 29.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 51kB 22.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 61kB 19.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 71kB 19.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 81kB 20.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 92kB 17.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 102kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 112kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 122kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 133kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 143kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 153kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 163kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 174kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 184kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 194kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 204kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 215kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 225kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 235kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 245kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 256kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 266kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 276kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 286kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 296kB 17.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.18.5)\n",
      "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.12.0)\n",
      "Installing collected packages: dm-tree, tensorflow-model-optimization\n",
      "Successfully installed dm-tree-0.1.5 tensorflow-model-optimization-0.3.0\n"
     ]
    }
   ],
   "source": [
    "#!pip uninstall tensorflow -y\n",
    "#!pip install tf-nightly\n",
    "!pip install tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFfucD5jw17e"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "b3vuTSfzXNLD",
    "outputId": "8f5881b9-a76a-427a-a3b9-62754990210f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pN0T9Y_w3Ko"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/Violette_art/via_export_json.json') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "# remove unlabelled data\n",
    "delete = [key for key in data if data[key]['regions'] == []] \n",
    "# delete the key \n",
    "for key in delete: del data[key] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGm8iGWzt33P"
   },
   "outputs": [],
   "source": [
    "def get_mat(p1, p2):\n",
    "  \"\"\"\n",
    "  Function to get the homography matrix that transforms points p1 to p2\n",
    "  \"\"\"\n",
    "  A = []\n",
    "  for i in range(0, len(p1)):\n",
    "      x, y = p1[i][0], p1[i][1]\n",
    "      u, v = p2[i][0], p2[i][1]\n",
    "      A.append([x, y, 1, 0, 0, 0, -u*x, -u*y, -u])\n",
    "      A.append([0, 0, 0, x, y, 1, -v*x, -v*y, -v])\n",
    "  A = np.asarray(A)\n",
    "  U, S, Vh = np.linalg.svd(A)\n",
    "  L = Vh[-1,:] / Vh[-1,-1]\n",
    "  H = L.reshape(3, 3)\n",
    "  return H\n",
    "\n",
    "height = 480\n",
    "width = 800\n",
    "channels = 3\n",
    "input_frame = np.zeros(shape=(len(data), 256, 256, 3))\n",
    "output_frame = np.zeros(shape=(len(data), 8))\n",
    "skip = []\n",
    "h = int(height/32)\n",
    "w = int(width/32)\n",
    "\n",
    "#anchor point is front top left\n",
    "A = np.array([[0,0], [25,0], [0, 100], [25, 100]])\n",
    "for i, val in tqdm(enumerate(data)):\n",
    "  try:\n",
    "    rgb_image = Image.open(\"/content/drive/My Drive/Violette_art/all_frames/{}\".format(data[val]['filename']))\n",
    "    #First open, crop and resize the image\n",
    "    area = (160, 60, 1760, 1020)\n",
    "    cropped_img = rgb_image.crop(area)\n",
    "    newsize = (800, 480) \n",
    "    resized_img = np.array(cropped_img.resize(newsize))\n",
    "    #input_frame[i, :, :, :] = np.array(resized_img)\n",
    "    min_x = 800\n",
    "    max_x = 0\n",
    "    min_y = 480\n",
    "    max_y = 0\n",
    "    B = {}\n",
    "    break_bool = False\n",
    "    for point in data[val]['regions']:\n",
    "      label = point['region_attributes']['points']\n",
    "      if label in ['ftr', 'ftl', 'btl', 'btr']:\n",
    "        x, y = point['shape_attributes']['cx'], point['shape_attributes']['cy']\n",
    "        if x > 160 and x < 1760:\n",
    "          x = (x - 160) / 2\n",
    "        else: \n",
    "          skip.append(i)\n",
    "          break_bool = True\n",
    "        if y > 60 and y < 1020:\n",
    "          y = (y - 60) / 2\n",
    "        else: \n",
    "          skip.append(i)\n",
    "          break_bool = True\n",
    "        B[label] = [x, y]\n",
    "        if x < min_x: min_x = x\n",
    "        if x > max_x: max_x = x\n",
    "        if y < min_y: min_y = y\n",
    "        if y > max_y: max_y = y\n",
    "    if break_bool:\n",
    "      continue\n",
    "    \n",
    "    min_y = int(min_y)\n",
    "    max_y = int(max_y)\n",
    "    min_x = int(min_x)\n",
    "    max_x = int(max_x)\n",
    "    #resize image again to 256X256\n",
    "    img = Image.fromarray(resized_img.astype(np.uint8))\n",
    "    img = img.resize((256, 256))\n",
    "    input_frame[i] = np.array(img)\n",
    "    #get the homography matrix\n",
    "    B_sorted = np.array([B['ftl'], B['ftr'], B['btl'], B['btr']])\n",
    "    M = get_mat(A, np.array(B_sorted))\n",
    "    M = np.ndarray.flatten(M)\n",
    "    #rescale the points to where they will be on the output image\n",
    "    label = M[:-1]\n",
    "    label[2] = B['ftl'][0] / 800\n",
    "    label[5] = B['ftl'][1] / 480\n",
    "    output_frame[i] = label\n",
    "    \n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    skip.append(i)\n",
    "\n",
    "#delete the poorly formed data points\n",
    "input_frame = np.delete(input_frame, skip, axis=0)\n",
    "output_frame = np.delete(output_frame, skip, axis=0)\n",
    "input_frame.shape, output_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDT2LplKQgDN"
   },
   "outputs": [],
   "source": [
    "#VGG style model that outputs the homography matrix\n",
    "inputs = layers.Input(shape = (256, 256, 3))\n",
    "x = layers.Conv2D(32, kernel_size=3, activation='relu')(inputs)\n",
    "x = layers.Conv2D(32, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Conv2D(32, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Conv2D(32, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Conv2D(64, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Conv2D(64, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Conv2D(64, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Conv2D(64, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1024)(x)\n",
    "output = layers.Dense(8)(x)\n",
    "model = keras.Model(inputs = inputs, outputs = outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Vq1nA6H1tzE"
   },
   "outputs": [],
   "source": [
    "end_step = np.ceil(1.0 * (.9 * input_frame.shape[0]) / 16).astype(np.int32)\n",
    "end_step *= 100 #epochs\n",
    "initial_sparsity=.5\n",
    "final_sparsity=.95\n",
    "begin_step=20\n",
    "frequency=5\n",
    "\n",
    "new_pruning_params = {\n",
    "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=initial_sparsity,\n",
    "                                                  final_sparsity=final_sparsity,\n",
    "                                                  begin_step=begin_step,\n",
    "                                                  end_step=end_step,\n",
    "                                                  frequency=frequency)\n",
    "}\n",
    "\n",
    "model = sparsity.prune_low_magnitude(model, **new_pruning_params)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "def perturb(image, label):\n",
    "  image = tf.image.random_brightness(image, max_delta=0.1) # Random brightness\n",
    "  if np.random.randint(2, size=1)[0] == 0:\n",
    "    image = tf.image.random_crop(image, size = [100, 100, 3])\n",
    "    image = tf.image.resize(image, size=[128, 128])\n",
    "  return image, label\n",
    "\n",
    "x_train = ((input_frame / 128.0) - 1).astype(np.float32)\n",
    "\n",
    "checkpoint_path = \"/content/drive/My Drive/Violette_art/homography_small.tf\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    " \n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    " \n",
    "callbacks = [\n",
    "  tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "  sparsity.UpdatePruningStep(),\n",
    "  cp_callback \n",
    "]\n",
    "\n",
    "model.fit(x_train, output_frame, shuffle=True, batch_size=8, validation_split=.1, epochs=100, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "agfEsdiNlaZq",
    "outputId": "45461d4b-15cd-450b-d45d-8f5901a8ec22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Violette_art/homography_small.tf/assets\n"
     ]
    }
   ],
   "source": [
    "tflite_path = '/content/drive/My Drive/Violette_art/homography_small.tflite'\n",
    "final_model = sparsity.strip_pruning(model)\n",
    "tf.keras.models.save_model(final_model, checkpoint_path, include_optimizer=False)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]\n",
    "tflite_quant_model = converter.convert()\n",
    "with open(tflite_path, 'wb') as f:\n",
    "  f.write(tflite_quant_model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Homography_net.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
